from __future__ import annotations

import re
from pathlib import Path
from typing import List

import pandas as pd
import streamlit as st
import tushare as ts

st.set_page_config(page_title="ç»“æœè§£æï¼ˆtxtï¼‰", layout="wide")

RESULTS_DIR = Path("./results")

HEADER_RE = re.compile(r"é€‰è‚¡ç»“æœ\s*\[(?P<strategy>.+?)\]")
TRADE_DATE_RE = re.compile(r"äº¤æ˜“æ—¥:\s*(?P<date>\d{4}-\d{2}-\d{2})")
COUNT_RE = re.compile(r"ç¬¦åˆæ¡ä»¶è‚¡ç¥¨æ•°:\s*(?P<count>\d+)")
NO_PICK_KEYWORD = "æ— ç¬¦åˆæ¡ä»¶è‚¡ç¥¨"
TXT_DATE_RE = re.compile(r"^(?P<yyyymmdd>\d{8})\.txt$")
# åŒ¹é…æ—¥å¿—å‰ç¼€ï¼Œä¾‹å¦‚ï¼š2024-01-15 10:30:45,123 - INFO - 
LOG_PREFIX_RE = re.compile(r"^\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2},\d{3}\s+-\s+\w+\s+-\s+")


def to_ts_code(code: str) -> str:
    """å°†6ä½è‚¡ç¥¨ä»£ç è½¬æ¢ä¸ºTuShareæ ¼å¼çš„ts_code"""
    code = code.strip()
    if len(code) != 6:
        return code
    # æ²ªå¸‚ï¼š600/601/603/688å¼€å¤´ -> ä»£ç .SH
    # æ·±å¸‚ï¼š000/002/300å¼€å¤´ -> ä»£ç .SZ
    if code.startswith(('600', '601', '603', '688')):
        return f"{code}.SH"
    elif code.startswith(('000', '002', '300')):
        return f"{code}.SZ"
    else:
        return f"{code}.SZ"  # é»˜è®¤æ·±å¸‚


def get_stock_industry_by_code_tushare(codes: List[str], token: str | None = None) -> pd.DataFrame:
    """
    è¾“å…¥ï¼šè‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œä¾‹å¦‚ ['603344','002006',...]
    è¾“å‡ºï¼šDataFrame(è‚¡ç¥¨ä»£ç , ts_code, è‚¡ç¥¨åç§°, è¡Œä¸š, å¸‚åœº, å¤‡æ³¨)
    """
    global pro
    pro = ts.pro_api()
    pro._DataApi__token    = "792181680650588160" 
    pro._DataApi__http_url = "http://tushare.top/dataapi"
    
    # è½¬æˆ ts_code
    ts_codes = [to_ts_code(c) for c in codes]
    ts_code_set = set(ts_codes)
    
    # stock_basic ä¸€æ¬¡æ‹‰å…¨å¸‚åœºåŸºç¡€ä¿¡æ¯ï¼Œå†æŒ‰ ts_code è¿‡æ»¤
    # æ³¨ï¼šfields å¯ä»¥æŒ‰éœ€åŠ å‡
    basic = pro.stock_basic(
        exchange="",
        list_status="L",
        fields="ts_code,symbol,name,industry,market,area"
    )
    df = basic[basic["ts_code"].isin(ts_code_set)].copy()
    
    # æœ‰äº› code å¯èƒ½ä¸åœ¨ list_status='L'ï¼ˆå¦‚é€€å¸‚/æš‚åœï¼‰ï¼Œå†å°è¯•æŸ¥ D / P
    missing = ts_code_set - set(df["ts_code"].tolist())
    if missing:
        basic_d = pro.stock_basic(exchange="", list_status="D", fields="ts_code,symbol,name,industry,market,area")
        df2 = basic_d[basic_d["ts_code"].isin(missing)].copy()
        missing2 = missing - set(df2["ts_code"].tolist())
        if missing2:
            basic_p = pro.stock_basic(exchange="", list_status="P", fields="ts_code,symbol,name,industry,market,area")
            df3 = basic_p[basic_p["ts_code"].isin(missing2)].copy()
            df = pd.concat([df, df2, df3], ignore_index=True)
        else:
            df = pd.concat([df, df2], ignore_index=True)
    
    # ç»„è£…è¾“å‡ºï¼šä¿æŒè¾“å…¥ codes é¡ºåº
    # symbol å°±æ˜¯çº¯6ä½ä»£ç ï¼›ts_code å¸¦äº¤æ˜“æ‰€
    mp = {row["symbol"]: row for _, row in df.iterrows()}
    out_rows = []
    for code in codes:
        sym = code.strip()
        row = mp.get(sym)
        if row is None:
            out_rows.append({
                "è‚¡ç¥¨ä»£ç ": sym,
                "ts_code": to_ts_code(sym),
                "è‚¡ç¥¨åç§°": "æœªçŸ¥",
                "è¡Œä¸š": "æœªçŸ¥",
                "å¸‚åœº": "æœªçŸ¥",
                "å¤‡æ³¨": "TuShare stock_basic æœªæ‰¾åˆ°ï¼ˆå¯èƒ½ä»£ç ä¸å¯¹/éAè‚¡/æƒé™æˆ–æ•°æ®ç¼ºå¤±ï¼‰"
            })
        else:
            out_rows.append({
                "è‚¡ç¥¨ä»£ç ": sym,
                "ts_code": row["ts_code"],
                "è‚¡ç¥¨åç§°": row["name"],
                "è¡Œä¸š": row["industry"] if pd.notna(row["industry"]) and row["industry"] else "æœªçŸ¥",
                "å¸‚åœº": row["market"] if pd.notna(row["market"]) and row["market"] else "æœªçŸ¥",
                "å¤‡æ³¨": ""
            })
    return pd.DataFrame(out_rows)


def list_result_dates(results_dir: Path) -> List[pd.Timestamp]:
    dates: List[pd.Timestamp] = []
    if not results_dir.exists():
        return dates
    for fp in results_dir.glob("*.txt"):
        m = TXT_DATE_RE.match(fp.name)
        if m:
            dates.append(pd.to_datetime(m.group("yyyymmdd"), format="%Y%m%d"))
    return sorted(set(dates))


def parse_results_dir(results_dir: Path) -> pd.DataFrame:
    rows = []
    if not results_dir.exists():
        return pd.DataFrame(columns=["date", "strategy", "code"])

    for fp in sorted(results_dir.glob("*.txt")):
        text = fp.read_text(encoding="utf-8", errors="ignore")
        lines = text.splitlines()

        cur_strategy = None
        cur_trade_date = None
        expecting_picks = False

        for raw in lines:
            line = raw.strip()
            
            # å»é™¤æ—¥å¿—å‰ç¼€ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            line = LOG_PREFIX_RE.sub('', line).strip()

            mh = HEADER_RE.search(line)
            if mh:
                cur_strategy = mh.group("strategy").strip()
                cur_trade_date = None
                expecting_picks = False
                continue

            md = TRADE_DATE_RE.search(line)
            if md:
                cur_trade_date = pd.to_datetime(md.group("date"))
                expecting_picks = False
                continue

            mc = COUNT_RE.search(line)
            if mc and cur_strategy and cur_trade_date is not None:
                expecting_picks = True
                continue

            if expecting_picks and cur_strategy and cur_trade_date is not None:
                if not line:
                    continue
                if NO_PICK_KEYWORD in line:
                    expecting_picks = False
                    continue

                if "," in line:
                    codes = [c.strip() for c in line.split(",") if c.strip()]
                else:
                    codes = [line] if line else []

                for code in codes:
                    rows.append({"date": cur_trade_date, "strategy": cur_strategy, "code": code})
                expecting_picks = False

    df = pd.DataFrame(rows)
    if df.empty:
        return pd.DataFrame(columns=["date", "strategy", "code"])
    df["date"] = pd.to_datetime(df["date"])
    return df.drop_duplicates().sort_values(["date", "strategy", "code"])


def filter_hist_by_day(hist: pd.DataFrame, day: pd.Timestamp) -> pd.DataFrame:
    day = pd.to_datetime(day).normalize()
    return hist[hist["date"].dt.normalize() == day].copy()


@st.cache_data
def load_history() -> pd.DataFrame:
    return parse_results_dir(RESULTS_DIR)


st.title("ğŸ“Œ ç»“æœè§£æï¼ˆtxtï¼‰")
st.caption("æœ¬é¡µåªåš results/YYYYMMDD.txt çš„è§£æä¸æµè§ˆï¼šå½“å¤©é€‰è‚¡ã€æˆ˜æ³•â†’è‚¡ç¥¨ã€è‚¡ç¥¨â†’æˆ˜æ³•ã€‚")

result_dates = list_result_dates(RESULTS_DIR)
if not result_dates:
    st.warning("results/ ä¸‹æœªæ‰¾åˆ° YYYYMMDD.txt")
    st.stop()

picked_day = st.sidebar.selectbox(
    "é€‰æ‹©ç»“æœæ—¥æœŸ",
    options=result_dates,
    index=len(result_dates) - 1,
    format_func=lambda d: d.strftime("%Y-%m-%d"),
)

hist = load_history()
day_hist = filter_hist_by_day(hist, picked_day)

st.subheader(f"ğŸ—“ï¸ å½“å¤©é€‰è‚¡ï¼š{picked_day.strftime('%Y-%m-%d')}")

if day_hist.empty:
    st.warning('å½“å¤©æ²¡æœ‰è§£æåˆ°é€‰è‚¡è®°å½•ï¼ˆå¯èƒ½å…¨æ˜¯"æ— ç¬¦åˆæ¡ä»¶è‚¡ç¥¨"ï¼Œæˆ–æ—¥å¿—æ ¼å¼æœ‰å˜åŒ–ï¼‰ã€‚')
    st.stop()

c1, c2 = st.columns([2, 1])

with c1:
    st.markdown("**æŒ‰æˆ˜æ³•æŸ¥çœ‹ï¼ˆæˆ˜æ³• â†’ è‚¡ç¥¨ï¼‰**")
    by_strategy = (
        day_hist.groupby("strategy")["code"]
        .apply(lambda s: sorted(set(s)))
        .reset_index(name="codes")
        .sort_values("strategy")
    )
    for _, r in by_strategy.iterrows():
        st.write(f"**{r['strategy']}**ï¼ˆ{len(r['codes'])}ï¼‰")
        st.code(", ".join(r["codes"]) if r["codes"] else "æ— ")

with c2:
    st.markdown("**å½“å¤©å‘½ä¸­è‚¡ç¥¨æ•°ï¼ˆæŒ‰æˆ˜æ³•ï¼‰**")
    stat = (
        day_hist.groupby("strategy")
        .size()
        .sort_values(ascending=False)
        .reset_index(name="å‘½ä¸­è‚¡ç¥¨æ•°")
    )
    st.dataframe(stat, use_container_width=True, height=280)

st.divider()

st.markdown("**æŒ‰è‚¡ç¥¨æŸ¥çœ‹ï¼ˆè‚¡ç¥¨ â†’ å‘½ä¸­æˆ˜æ³•ï¼‰**")
by_code = (
    day_hist.groupby("code")["strategy"]
    .apply(lambda s: sorted(set(s)))
    .reset_index(name="strategies")
    .sort_values("code")
)

# æ·»åŠ è¡Œä¸šä¿¡æ¯åŠŸèƒ½
if st.checkbox("æ˜¾ç¤ºè‚¡ç¥¨è¡Œä¸šä¿¡æ¯", value=False):
    with st.spinner("æ­£åœ¨è·å–è‚¡ç¥¨è¡Œä¸šä¿¡æ¯..."):
        try:
            codes_list = by_code["code"].tolist()
            industry_df = get_stock_industry_by_code_tushare(codes_list)
            
            # åˆå¹¶è¡Œä¸šä¿¡æ¯åˆ°by_code
            by_code_with_industry = by_code.merge(
                industry_df[["è‚¡ç¥¨ä»£ç ", "è‚¡ç¥¨åç§°", "è¡Œä¸š", "å¸‚åœº"]],
                left_on="code",
                right_on="è‚¡ç¥¨ä»£ç ",
                how="left"
            )
            by_code_with_industry = by_code_with_industry.drop(columns=["è‚¡ç¥¨ä»£ç "])
            
            st.dataframe(
                by_code_with_industry.rename(columns={
                    "code": "è‚¡ç¥¨ä»£ç ",
                    "strategies": "å‘½ä¸­æˆ˜æ³•",
                    "è‚¡ç¥¨åç§°": "åç§°",
                    "è¡Œä¸š": "è¡Œä¸š",
                    "å¸‚åœº": "å¸‚åœº"
                }),
                use_container_width=True,
                height=420,
            )
        except Exception as e:
            st.error(f"è·å–è¡Œä¸šä¿¡æ¯å¤±è´¥ï¼š{str(e)}")
            st.dataframe(
                by_code.rename(columns={"code": "è‚¡ç¥¨", "strategies": "å‘½ä¸­æˆ˜æ³•"}),
                use_container_width=True,
                height=420,
            )
else:
    st.dataframe(
        by_code.rename(columns={"code": "è‚¡ç¥¨", "strategies": "å‘½ä¸­æˆ˜æ³•"}),
        use_container_width=True,
        height=420,
    )